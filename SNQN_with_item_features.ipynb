{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changyuhsin1999/Recommender_RL/blob/main/SNQN_with_item_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgquSOog8hJl",
        "outputId": "7f1b4c31-1459-46a0-bcc7-b8f51e4c3738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle\n",
            "data\t\t\t\tNextItNetModules.py   SA2C_new_feature_50.py  SNQN_new.py\n",
            "DQN_NS.py\t\t\tpop.py\t\t      SA2C_new_feature.py     SNQN.py\n",
            "feature_one_hot_encoding.ipynb\tpreprocess_kaggle.py  SA2C_new.py\t      split_data.py\n",
            "item_onehotencode.csv\t\t__pycache__\t      SA2C.py\t\t      test.py\n",
            "item_properties_part1.csv\treplay_buffer.py      SASRecModules.py\t      utility.py\n",
            "item_properties_part2.csv\treport_SA2C.txt       SNQN_new_features.py\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PROJ_DIR = '/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle'   ## give your drive folder location\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XXx5twV9lK8",
        "outputId": "59610d7b-bab6-40f2-8d71-fa77d2754630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-20 00:13:07.858957: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-20 00:13:07.859010: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-20 00:13:07.859050: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-20 00:13:07.867375: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-20 00:13:09.255176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO line 65:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 68:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 70:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 71:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "WARNING line 75:29: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 78:46: Renamed 'tf.nn.dynamic_rnn' to 'tf.compat.v1.nn.dynamic_rnn'\n",
            "INFO line 79:20: Renamed 'tf.contrib.rnn.GRUCell' to 'tf.compat.v1.nn.rnn_cell.GRUCell'\n",
            "INFO line 86:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 96:25: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 96:25: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 99:40: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 102:31: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 102:31: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 113:33: Added keywords to args of function 'tf.nn.max_pool'\n",
            "INFO line 113:33: Renamed keyword argument for tf.nn.max_pool from value to input\n",
            "INFO line 113:33: Renamed 'tf.nn.max_pool' to 'tf.nn.max_pool2d'\n",
            "INFO line 126:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 126:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 128:36: Renamed 'tf.truncated_normal' to 'tf.random.truncated_normal'\n",
            "INFO line 130:27: Added keywords to args of function 'tf.nn.conv2d'\n",
            "INFO line 130:27: Renamed keyword argument for tf.nn.conv2d from filter to filters\n",
            "INFO line 141:21: `name` passed to `name_scope`. Because you may be re-entering an existing scope, it is not safe to convert automatically,  the v2 name_scope does not support re-entering scopes by name.\n",
            "\n",
            "INFO line 141:21: Renamed 'tf.name_scope' to 'tf.compat.v1.name_scope'\n",
            "INFO line 142:41: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 147:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "WARNING line 156:36: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "WARNING line 171:26: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "INFO line 176:38: Changed tf.to_float call to tf.cast(..., dtype=tf.float32).\n",
            "INFO line 178:27: Renamed 'tf.layers.dropout' to 'tf.compat.v1.layers.dropout'\n",
            "INFO line 186:25: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "ERROR line 206:27: Using member tf.contrib.layers.fully_connected in deprecated module tf.contrib. tf.contrib.layers.fully_connected cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "ERROR line 209:26: Using member tf.contrib.layers.fully_connected in deprecated module tf.contrib. tf.contrib.layers.fully_connected cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "INFO line 213:27: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 215:34: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 217:29: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 218:37: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 220:26: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 221:28: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 223:36: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 224:44: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 243:23: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 248:17: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 249:47: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 251:45: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 336:4: Renamed 'tf.reset_default_graph' to 'tf.compat.v1.reset_default_graph'\n",
            "INFO line 347:9: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 349:17: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 1 files\n",
            "Detected 5 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: SNQN.py\n",
            "--------------------------------------------------------------------------------\n",
            "SNQN.py:75:29: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "SNQN.py:156:36: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "SNQN.py:171:26: WARNING: tf.nn.embedding_lookup requires manual check. `partition_strategy` has been removed from tf.nn.embedding_lookup.  The 'div' strategy will be used by default.\n",
            "SNQN.py:206:27: ERROR: Using member tf.contrib.layers.fully_connected in deprecated module tf.contrib. tf.contrib.layers.fully_connected cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "SNQN.py:209:26: ERROR: Using member tf.contrib.layers.fully_connected in deprecated module tf.contrib. tf.contrib.layers.fully_connected cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report_SA2C.txt'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile 'SNQN.py' \\\n",
        "  --outfile 'SNQN_new.py' \\\n",
        "  --reportfile report_SA2C.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4DUdv2V9vWu",
        "outputId": "d5210565-0036-4e93-db34-de11966cfde9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n",
            "Collecting tensorrt\n",
            "  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1.post1-py2.py3-none-any.whl size=17281 sha256=796f88662deb4e84f5dc5676ef260faef3c7a2d792892fa6dcee50b5215a9463\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/c8/0e/b79b08e45752491b9acfdbd69e8a609e8b2ed7640dda5a3e59\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-8.6.1.post1\n"
          ]
        }
      ],
      "source": [
        "! pip install pandas trfl\n",
        "! pip install tensorrt\n",
        "#!pip install tensorflow --upgrade\n",
        "#!pip install --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks3fYspKmFXG",
        "outputId": "d6332134-957e-45a6-dfdd-3101b9620f74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-24 00:20:41.911550: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-24 00:20:41.911626: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-24 00:20:41.911674: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-24 00:20:41.923260: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-24 00:20:43.153578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new.py:80: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new.py:79: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2023-11-24 00:20:46.779125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:47.276807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:47.277128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:47.278939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:47.279191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:47.279380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:49.907395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:49.907692: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:49.907878: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-24 00:20:49.907964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:49.908142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new.py:207: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new.py:210: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "2023-11-24 00:20:58.268109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:58.268421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:58.268584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:58.268823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:58.269004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-24 00:20:58.269144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-24 00:20:58.296685: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 0.800000\n",
            "clicks hr ndcg @ 5 : 0.000034, 0.000014\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 1.600000\n",
            "clicks hr ndcg @ 10 : 0.000068, 0.000025\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 3.600000\n",
            "clicks hr ndcg @ 15 : 0.000152, 0.000048\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 5.200000\n",
            "clicks hr ndcg @ 20 : 0.000220, 0.000063\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "the loss in 200th batch is: 10.779688\n",
            "the loss in 400th batch is: 10.622356\n",
            "the loss in 600th batch is: 10.492518\n",
            "the loss in 800th batch is: 10.478059\n",
            "the loss in 1000th batch is: 10.433392\n",
            "the loss in 1200th batch is: 10.114708\n",
            "the loss in 1400th batch is: 10.100520\n",
            "the loss in 1600th batch is: 9.922647\n",
            "the loss in 1800th batch is: 9.561771\n",
            "the loss in 2000th batch is: 9.778189\n",
            "the loss in 2200th batch is: 9.566069\n",
            "the loss in 2400th batch is: 9.569586\n",
            "the loss in 2600th batch is: 9.364710\n",
            "the loss in 2800th batch is: 9.396424\n",
            "the loss in 3000th batch is: 8.587440\n",
            "the loss in 3200th batch is: 8.909747\n",
            "the loss in 3400th batch is: 8.881142\n",
            "the loss in 3600th batch is: 9.057409\n",
            "the loss in 3800th batch is: 8.816780\n",
            "the loss in 4000th batch is: 8.670504\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5949.800000\n",
            "clicks hr ndcg @ 5 : 0.169890, 0.133992\n",
            "purchase hr and ndcg @5 : 0.364770, 0.312273\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 6863.400000\n",
            "clicks hr ndcg @ 10 : 0.200852, 0.144001\n",
            "purchase hr and ndcg @10 : 0.398979, 0.323384\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7389.800000\n",
            "clicks hr ndcg @ 15 : 0.218704, 0.148720\n",
            "purchase hr and ndcg @15 : 0.418635, 0.328629\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7770.800000\n",
            "clicks hr ndcg @ 20 : 0.231848, 0.151828\n",
            "purchase hr and ndcg @20 : 0.431865, 0.331753\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.536073\n",
            "the loss in 4400th batch is: 8.024720\n",
            "the loss in 4600th batch is: 7.834303\n",
            "the loss in 4800th batch is: 8.163212\n",
            "the loss in 5000th batch is: 8.367522\n",
            "the loss in 5200th batch is: 7.939554\n",
            "the loss in 5400th batch is: 8.002554\n",
            "the loss in 5600th batch is: 8.373919\n",
            "the loss in 5800th batch is: 7.633009\n",
            "the loss in 6000th batch is: 7.983349\n",
            "the loss in 6200th batch is: 7.497892\n",
            "the loss in 6400th batch is: 7.935277\n",
            "the loss in 6600th batch is: 7.355548\n",
            "the loss in 6800th batch is: 7.555241\n",
            "the loss in 7000th batch is: 7.557584\n",
            "the loss in 7200th batch is: 8.184265\n",
            "the loss in 7400th batch is: 7.431923\n",
            "the loss in 7600th batch is: 7.238172\n",
            "the loss in 7800th batch is: 7.093559\n",
            "the loss in 8000th batch is: 7.543282\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8083.200000\n",
            "clicks hr ndcg @ 5 : 0.233724, 0.183733\n",
            "purchase hr and ndcg @5 : 0.482517, 0.411305\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9314.600000\n",
            "clicks hr ndcg @ 10 : 0.275666, 0.197293\n",
            "purchase hr and ndcg @10 : 0.527689, 0.425961\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10000.400000\n",
            "clicks hr ndcg @ 15 : 0.300002, 0.203740\n",
            "purchase hr and ndcg @15 : 0.548479, 0.431463\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10470.000000\n",
            "clicks hr ndcg @ 20 : 0.316087, 0.207544\n",
            "purchase hr and ndcg @20 : 0.565300, 0.435431\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.507858\n",
            "the loss in 8400th batch is: 6.745512\n",
            "the loss in 8600th batch is: 6.552438\n",
            "the loss in 8800th batch is: 7.320374\n",
            "the loss in 9000th batch is: 6.692183\n",
            "the loss in 9200th batch is: 7.080301\n",
            "the loss in 9400th batch is: 6.723967\n",
            "the loss in 9600th batch is: 6.848673\n",
            "the loss in 9800th batch is: 6.798319\n",
            "the loss in 10000th batch is: 7.219014\n",
            "the loss in 10200th batch is: 6.807783\n",
            "the loss in 10400th batch is: 6.504992\n",
            "the loss in 10600th batch is: 6.738473\n",
            "the loss in 10800th batch is: 6.603675\n",
            "the loss in 11000th batch is: 6.323349\n",
            "the loss in 11200th batch is: 6.463623\n",
            "the loss in 11400th batch is: 6.681244\n",
            "the loss in 11600th batch is: 6.910348\n",
            "the loss in 11800th batch is: 6.353323\n",
            "the loss in 12000th batch is: 6.116663\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8788.600000\n",
            "clicks hr ndcg @ 5 : 0.255084, 0.199170\n",
            "purchase hr and ndcg @5 : 0.520318, 0.441987\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10129.400000\n",
            "clicks hr ndcg @ 10 : 0.301692, 0.214274\n",
            "purchase hr and ndcg @10 : 0.565300, 0.456746\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 10871.200000\n",
            "clicks hr ndcg @ 15 : 0.327591, 0.221134\n",
            "purchase hr and ndcg @15 : 0.589681, 0.463212\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11389.600000\n",
            "clicks hr ndcg @ 20 : 0.345739, 0.225425\n",
            "purchase hr and ndcg @20 : 0.606502, 0.467168\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 5.954879\n",
            "the loss in 12400th batch is: 6.666242\n",
            "the loss in 12600th batch is: 6.756356\n",
            "the loss in 12800th batch is: 6.122782\n",
            "the loss in 13000th batch is: 6.026952\n",
            "the loss in 13200th batch is: 6.319631\n",
            "the loss in 13400th batch is: 6.355564\n",
            "the loss in 13600th batch is: 6.184882\n",
            "the loss in 13800th batch is: 6.466098\n",
            "the loss in 14000th batch is: 6.247218\n",
            "the loss in 14200th batch is: 6.004800\n",
            "the loss in 14400th batch is: 5.992989\n",
            "the loss in 14600th batch is: 6.478604\n",
            "the loss in 14800th batch is: 6.298301\n",
            "the loss in 15000th batch is: 6.396816\n",
            "the loss in 15200th batch is: 6.008677\n",
            "the loss in 15400th batch is: 6.129688\n",
            "the loss in 15600th batch is: 6.070496\n",
            "the loss in 15800th batch is: 6.310472\n",
            "the loss in 16000th batch is: 6.059469\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 8988.400000\n",
            "clicks hr ndcg @ 5 : 0.263233, 0.204164\n",
            "purchase hr and ndcg @5 : 0.521641, 0.440958\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 10441.800000\n",
            "clicks hr ndcg @ 10 : 0.312824, 0.220249\n",
            "purchase hr and ndcg @10 : 0.574561, 0.458260\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 11214.200000\n",
            "clicks hr ndcg @ 15 : 0.339383, 0.227282\n",
            "purchase hr and ndcg @15 : 0.601777, 0.465451\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 11751.800000\n",
            "clicks hr ndcg @ 20 : 0.358300, 0.231754\n",
            "purchase hr and ndcg @20 : 0.618787, 0.469473\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 6.559916\n",
            "the loss in 16400th batch is: 5.844229\n",
            "the loss in 16600th batch is: 6.250834\n",
            "the loss in 16800th batch is: 5.909193\n",
            "the loss in 17000th batch is: 5.884779\n",
            "the loss in 17200th batch is: 5.710353\n",
            "the loss in 17400th batch is: 5.640998\n",
            "the loss in 17600th batch is: 5.861727\n",
            "the loss in 17800th batch is: 5.527953\n",
            "the loss in 18000th batch is: 5.853766\n",
            "the loss in 18200th batch is: 5.631748\n",
            "the loss in 18400th batch is: 5.423932\n",
            "the loss in 18600th batch is: 6.226079\n",
            "the loss in 18800th batch is: 5.885643\n",
            "the loss in 19000th batch is: 5.769738\n",
            "the loss in 19200th batch is: 5.595870\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new.py --model=GRU --epoch=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkk_g8XbgGaZ",
        "outputId": "6aa92c06-0b3d-4f9a-a13e-fc5601a6886a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-22 05:31:16.649426: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-22 05:31:16.649474: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-22 05:31:16.649509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-22 05:31:16.657202: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-22 05:31:17.849326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:82: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:81: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2023-11-22 05:31:27.208633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:27.742752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:27.743060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:27.744302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:27.744524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:27.744694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:30.118678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:30.119004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:30.119163: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-22 05:31:30.119252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:30.119419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:209: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:214: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.hidden_feature = tf.compat.v1.layers.dense(self.feature_vec,self.hidden_size,use_bias=True,activation = None)\n",
            "2023-11-22 05:31:38.517321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:38.517651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:38.517861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:38.518145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:38.518361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 05:31:38.518497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-22 05:31:39.891931: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1.200000\n",
            "clicks hr ndcg @ 5 : 0.000051, 0.000024\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 3.400000\n",
            "clicks hr ndcg @ 10 : 0.000144, 0.000054\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 6.800000\n",
            "clicks hr ndcg @ 15 : 0.000287, 0.000092\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9.000000\n",
            "clicks hr ndcg @ 20 : 0.000380, 0.000114\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "2023-11-22 05:46:50.287010: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 05:46:51.389577: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 05:46:51.479069: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 05:46:51.569625: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 05:46:51.658712: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "the loss in 200th batch is: 10.968204\n",
            "the loss in 400th batch is: 10.702730\n",
            "the loss in 600th batch is: 10.418479\n",
            "the loss in 800th batch is: 10.336361\n",
            "the loss in 1000th batch is: 9.990314\n",
            "the loss in 1200th batch is: 10.276958\n",
            "the loss in 1400th batch is: 9.852878\n",
            "the loss in 1600th batch is: 9.669574\n",
            "the loss in 1800th batch is: 9.298237\n",
            "the loss in 2000th batch is: 9.711342\n",
            "the loss in 2200th batch is: 9.649080\n",
            "the loss in 2400th batch is: 9.474254\n",
            "the loss in 2600th batch is: 9.319023\n",
            "the loss in 2800th batch is: 9.288771\n",
            "the loss in 3000th batch is: 8.657103\n",
            "the loss in 3200th batch is: 8.986495\n",
            "the loss in 3400th batch is: 8.921329\n",
            "the loss in 3600th batch is: 8.884542\n",
            "the loss in 3800th batch is: 8.961123\n",
            "the loss in 4000th batch is: 8.254393\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4124.000000\n",
            "clicks hr ndcg @ 5 : 0.117746, 0.088375\n",
            "purchase hr and ndcg @5 : 0.252882, 0.197180\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5039.800000\n",
            "clicks hr ndcg @ 10 : 0.146434, 0.097647\n",
            "purchase hr and ndcg @10 : 0.297675, 0.211743\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5617.600000\n",
            "clicks hr ndcg @ 15 : 0.164514, 0.102430\n",
            "purchase hr and ndcg @15 : 0.326025, 0.219269\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6028.600000\n",
            "clicks hr ndcg @ 20 : 0.177869, 0.105586\n",
            "purchase hr and ndcg @20 : 0.343980, 0.223498\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.258290\n",
            "the loss in 4400th batch is: 8.443711\n",
            "the loss in 4600th batch is: 8.774473\n",
            "the loss in 4800th batch is: 8.268915\n",
            "the loss in 5000th batch is: 7.956740\n",
            "the loss in 5200th batch is: 8.434693\n",
            "the loss in 5400th batch is: 7.983512\n",
            "the loss in 5600th batch is: 8.307155\n",
            "the loss in 5800th batch is: 7.713727\n",
            "the loss in 6000th batch is: 7.649913\n",
            "the loss in 6200th batch is: 7.921993\n",
            "the loss in 6400th batch is: 8.010429\n",
            "the loss in 6600th batch is: 7.605950\n",
            "the loss in 6800th batch is: 7.633213\n",
            "the loss in 7000th batch is: 7.627885\n",
            "the loss in 7200th batch is: 7.380477\n",
            "the loss in 7400th batch is: 7.362546\n",
            "the loss in 7600th batch is: 7.337956\n",
            "the loss in 7800th batch is: 7.089680\n",
            "the loss in 8000th batch is: 7.112233\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 5835.400000\n",
            "clicks hr ndcg @ 5 : 0.167337, 0.124657\n",
            "purchase hr and ndcg @5 : 0.354564, 0.279963\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 7147.600000\n",
            "clicks hr ndcg @ 10 : 0.210666, 0.138731\n",
            "purchase hr and ndcg @10 : 0.408807, 0.297657\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 7869.400000\n",
            "clicks hr ndcg @ 15 : 0.234536, 0.145049\n",
            "purchase hr and ndcg @15 : 0.438480, 0.305437\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 8405.000000\n",
            "clicks hr ndcg @ 20 : 0.252396, 0.149269\n",
            "purchase hr and ndcg @20 : 0.459837, 0.310484\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.741673\n",
            "the loss in 8400th batch is: 8.046803\n",
            "the loss in 8600th batch is: 7.553674\n",
            "the loss in 8800th batch is: 7.090931\n",
            "the loss in 9000th batch is: 6.477291\n",
            "the loss in 9200th batch is: 6.945329\n",
            "the loss in 9400th batch is: 7.101334\n",
            "the loss in 9600th batch is: 7.111617\n",
            "the loss in 9800th batch is: 6.981796\n",
            "the loss in 10000th batch is: 6.925696\n",
            "the loss in 10200th batch is: 7.108428\n",
            "the loss in 10400th batch is: 6.971430\n",
            "the loss in 10600th batch is: 6.910966\n",
            "the loss in 10800th batch is: 7.027278\n",
            "the loss in 11000th batch is: 6.304288\n",
            "the loss in 11200th batch is: 6.519149\n",
            "the loss in 11400th batch is: 6.442706\n",
            "the loss in 11600th batch is: 6.622581\n",
            "the loss in 11800th batch is: 6.792642\n",
            "the loss in 12000th batch is: 6.977143\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6351.000000\n",
            "clicks hr ndcg @ 5 : 0.184944, 0.136311\n",
            "purchase hr and ndcg @5 : 0.373275, 0.291767\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 7895.000000\n",
            "clicks hr ndcg @ 10 : 0.234561, 0.152365\n",
            "purchase hr and ndcg @10 : 0.443205, 0.314488\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8779.600000\n",
            "clicks hr ndcg @ 15 : 0.264467, 0.160294\n",
            "purchase hr and ndcg @15 : 0.476658, 0.323389\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9414.400000\n",
            "clicks hr ndcg @ 20 : 0.285083, 0.165165\n",
            "purchase hr and ndcg @20 : 0.504442, 0.329962\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.593744\n",
            "the loss in 12400th batch is: 6.812035\n",
            "the loss in 12600th batch is: 6.780736\n",
            "the loss in 12800th batch is: 6.842644\n",
            "the loss in 13000th batch is: 6.771804\n",
            "the loss in 13200th batch is: 5.859061\n",
            "the loss in 13400th batch is: 6.143239\n",
            "the loss in 13600th batch is: 6.462138\n",
            "the loss in 13800th batch is: 6.244039\n",
            "the loss in 14000th batch is: 5.817009\n",
            "the loss in 14200th batch is: 6.158475\n",
            "the loss in 14400th batch is: 6.210668\n",
            "the loss in 14600th batch is: 6.186459\n",
            "the loss in 14800th batch is: 6.290020\n",
            "the loss in 15000th batch is: 6.181032\n",
            "the loss in 15200th batch is: 5.876406\n",
            "the loss in 15400th batch is: 6.352513\n",
            "the loss in 15600th batch is: 6.696309\n",
            "the loss in 15800th batch is: 6.415089\n",
            "the loss in 16000th batch is: 5.818761\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6666.400000\n",
            "clicks hr ndcg @ 5 : 0.195485, 0.143907\n",
            "purchase hr and ndcg @5 : 0.385749, 0.301691\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8350.800000\n",
            "clicks hr ndcg @ 10 : 0.248711, 0.161116\n",
            "purchase hr and ndcg @10 : 0.466074, 0.327643\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9276.600000\n",
            "clicks hr ndcg @ 15 : 0.279090, 0.169156\n",
            "purchase hr and ndcg @15 : 0.505198, 0.338027\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9913.200000\n",
            "clicks hr ndcg @ 20 : 0.300585, 0.174238\n",
            "purchase hr and ndcg @20 : 0.529390, 0.343726\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 6.282328\n",
            "the loss in 16400th batch is: 5.915447\n",
            "the loss in 16600th batch is: 6.100604\n",
            "the loss in 16800th batch is: 6.317108\n",
            "the loss in 17000th batch is: 5.763078\n",
            "the loss in 17200th batch is: 6.389854\n",
            "the loss in 17400th batch is: 5.601586\n",
            "the loss in 17600th batch is: 5.844471\n",
            "the loss in 17800th batch is: 5.839477\n",
            "the loss in 18000th batch is: 6.052149\n",
            "the loss in 18200th batch is: 5.991209\n",
            "the loss in 18400th batch is: 5.796869\n",
            "the loss in 18600th batch is: 5.907258\n",
            "the loss in 18800th batch is: 5.895091\n",
            "the loss in 19000th batch is: 5.660117\n",
            "the loss in 19200th batch is: 6.266068\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new_features.py --model=GRU --epoch=5    ##lambda_ = 0.2##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhpPwd4w79ZN",
        "outputId": "b5a8b2b8-e6ed-47f7-a409-ec17aa32e190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-22 21:29:13.538165: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-22 21:29:13.538211: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-22 21:29:13.538246: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-22 21:29:13.548997: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-22 21:29:15.185474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:82: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:81: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2023-11-22 21:29:23.822345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:24.283216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:24.283538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:24.287063: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:24.287312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:24.287488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:26.613479: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:26.613750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:26.613873: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-22 21:29:26.613946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:26.614081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:209: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:214: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.hidden_feature = tf.compat.v1.layers.dense(self.feature_vec,self.hidden_size,use_bias=True,activation = None)\n",
            "2023-11-22 21:29:36.154563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:36.154844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:36.154999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:36.155209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:36.155366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-22 21:29:36.155488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-22 21:29:36.741974: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 2.000000\n",
            "clicks hr ndcg @ 5 : 0.000085, 0.000043\n",
            "purchase hr and ndcg @5 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 3.600000\n",
            "clicks hr ndcg @ 10 : 0.000152, 0.000064\n",
            "purchase hr and ndcg @10 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 4.800000\n",
            "clicks hr ndcg @ 15 : 0.000203, 0.000077\n",
            "purchase hr and ndcg @15 : 0.000000, 0.000000\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7.200000\n",
            "clicks hr ndcg @ 20 : 0.000304, 0.000102\n",
            "purchase hr and ndcg @20 : 0.000000, 0.000000\n",
            "#############################################################\n",
            "2023-11-22 21:44:24.852932: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 21:44:25.927442: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 21:44:26.022684: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 21:44:26.111749: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-22 21:44:26.198305: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "the loss in 200th batch is: 10.768354\n",
            "the loss in 400th batch is: 10.636969\n",
            "the loss in 600th batch is: 10.354157\n",
            "the loss in 800th batch is: 10.396123\n",
            "the loss in 1000th batch is: 10.129520\n",
            "the loss in 1200th batch is: 9.952944\n",
            "the loss in 1400th batch is: 9.593501\n",
            "the loss in 1600th batch is: 9.657540\n",
            "the loss in 1800th batch is: 9.803404\n",
            "the loss in 2000th batch is: 9.784414\n",
            "the loss in 2200th batch is: 9.294348\n",
            "the loss in 2400th batch is: 9.167330\n",
            "the loss in 2600th batch is: 9.156340\n",
            "the loss in 2800th batch is: 9.131735\n",
            "the loss in 3000th batch is: 8.853014\n",
            "the loss in 3200th batch is: 9.093599\n",
            "the loss in 3400th batch is: 8.787831\n",
            "the loss in 3600th batch is: 8.935878\n",
            "the loss in 3800th batch is: 8.605387\n",
            "the loss in 4000th batch is: 8.060956\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4762.800000\n",
            "clicks hr ndcg @ 5 : 0.136079, 0.103687\n",
            "purchase hr and ndcg @5 : 0.291627, 0.234304\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5699.000000\n",
            "clicks hr ndcg @ 10 : 0.166433, 0.113515\n",
            "purchase hr and ndcg @10 : 0.332829, 0.247767\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 6269.400000\n",
            "clicks hr ndcg @ 15 : 0.184327, 0.118247\n",
            "purchase hr and ndcg @15 : 0.360612, 0.255150\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6646.400000\n",
            "clicks hr ndcg @ 20 : 0.196752, 0.121183\n",
            "purchase hr and ndcg @20 : 0.376299, 0.258852\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.256418\n",
            "the loss in 4400th batch is: 8.143345\n",
            "the loss in 4600th batch is: 8.109109\n",
            "the loss in 4800th batch is: 8.430414\n",
            "the loss in 5000th batch is: 8.132206\n",
            "the loss in 5200th batch is: 8.049926\n",
            "the loss in 5400th batch is: 7.897596\n",
            "the loss in 5600th batch is: 7.958385\n",
            "the loss in 5800th batch is: 8.113912\n",
            "the loss in 6000th batch is: 7.471669\n",
            "the loss in 6200th batch is: 8.012219\n",
            "the loss in 6400th batch is: 7.898965\n",
            "the loss in 6600th batch is: 7.863465\n",
            "the loss in 6800th batch is: 7.526700\n",
            "the loss in 7000th batch is: 7.165397\n",
            "the loss in 7200th batch is: 7.450145\n",
            "the loss in 7400th batch is: 7.415542\n",
            "the loss in 7600th batch is: 7.164236\n",
            "the loss in 7800th batch is: 7.074146\n",
            "the loss in 8000th batch is: 7.179423\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6657.600000\n",
            "clicks hr ndcg @ 5 : 0.192070, 0.146044\n",
            "purchase hr and ndcg @5 : 0.399357, 0.319945\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 7955.800000\n",
            "clicks hr ndcg @ 10 : 0.234595, 0.159816\n",
            "purchase hr and ndcg @10 : 0.454545, 0.337887\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8680.800000\n",
            "clicks hr ndcg @ 15 : 0.259319, 0.166368\n",
            "purchase hr and ndcg @15 : 0.481005, 0.344877\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9176.800000\n",
            "clicks hr ndcg @ 20 : 0.276478, 0.170424\n",
            "purchase hr and ndcg @20 : 0.498015, 0.348903\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.257297\n",
            "the loss in 8400th batch is: 7.543699\n",
            "the loss in 8600th batch is: 6.684251\n",
            "the loss in 8800th batch is: 7.034842\n",
            "the loss in 9000th batch is: 6.851324\n",
            "the loss in 9200th batch is: 6.885722\n",
            "the loss in 9400th batch is: 6.930000\n",
            "the loss in 9600th batch is: 6.795289\n",
            "the loss in 9800th batch is: 6.908748\n",
            "the loss in 10000th batch is: 6.988797\n",
            "the loss in 10200th batch is: 6.959026\n",
            "the loss in 10400th batch is: 6.935455\n",
            "the loss in 10600th batch is: 6.525889\n",
            "the loss in 10800th batch is: 6.968275\n",
            "the loss in 11000th batch is: 6.711108\n",
            "the loss in 11200th batch is: 6.542883\n",
            "the loss in 11400th batch is: 6.699322\n",
            "the loss in 11600th batch is: 6.712101\n",
            "the loss in 11800th batch is: 6.765857\n",
            "the loss in 12000th batch is: 6.351620\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7257.000000\n",
            "clicks hr ndcg @ 5 : 0.209922, 0.158230\n",
            "purchase hr and ndcg @5 : 0.432810, 0.348341\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8761.000000\n",
            "clicks hr ndcg @ 10 : 0.259116, 0.174148\n",
            "purchase hr and ndcg @10 : 0.497070, 0.369160\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9560.400000\n",
            "clicks hr ndcg @ 15 : 0.286942, 0.181526\n",
            "purchase hr and ndcg @15 : 0.523720, 0.376232\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10145.600000\n",
            "clicks hr ndcg @ 20 : 0.307491, 0.186380\n",
            "purchase hr and ndcg @20 : 0.542431, 0.380667\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.716101\n",
            "the loss in 12400th batch is: 6.499084\n",
            "the loss in 12600th batch is: 6.477384\n",
            "the loss in 12800th batch is: 6.456609\n",
            "the loss in 13000th batch is: 6.623161\n",
            "the loss in 13200th batch is: 6.242664\n",
            "the loss in 13400th batch is: 6.075417\n",
            "the loss in 13600th batch is: 6.422287\n",
            "the loss in 13800th batch is: 6.064916\n",
            "the loss in 14000th batch is: 6.264973\n",
            "the loss in 14200th batch is: 6.293474\n",
            "the loss in 14400th batch is: 6.689933\n",
            "the loss in 14600th batch is: 6.353784\n",
            "the loss in 14800th batch is: 6.117288\n",
            "the loss in 15000th batch is: 6.001286\n",
            "the loss in 15200th batch is: 6.248639\n",
            "the loss in 15400th batch is: 5.921943\n",
            "the loss in 15600th batch is: 6.027540\n",
            "the loss in 15800th batch is: 6.495489\n",
            "the loss in 16000th batch is: 5.765250\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7474.800000\n",
            "clicks hr ndcg @ 5 : 0.218366, 0.164532\n",
            "purchase hr and ndcg @5 : 0.436212, 0.351933\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 9058.600000\n",
            "clicks hr ndcg @ 10 : 0.270595, 0.181438\n",
            "purchase hr and ndcg @10 : 0.501985, 0.373355\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9962.600000\n",
            "clicks hr ndcg @ 15 : 0.301489, 0.189625\n",
            "purchase hr and ndcg @15 : 0.534682, 0.381959\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10560.600000\n",
            "clicks hr ndcg @ 20 : 0.322283, 0.194538\n",
            "purchase hr and ndcg @20 : 0.554716, 0.386702\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.948805\n",
            "the loss in 16400th batch is: 5.915982\n",
            "the loss in 16600th batch is: 5.811930\n",
            "the loss in 16800th batch is: 5.812624\n",
            "the loss in 17000th batch is: 6.194410\n",
            "the loss in 17200th batch is: 5.439575\n",
            "the loss in 17400th batch is: 5.937668\n",
            "the loss in 17600th batch is: 5.345663\n",
            "the loss in 17800th batch is: 6.016101\n",
            "the loss in 18000th batch is: 6.226481\n",
            "the loss in 18200th batch is: 5.766683\n",
            "the loss in 18400th batch is: 5.553419\n",
            "the loss in 18600th batch is: 5.619971\n",
            "the loss in 18800th batch is: 5.900367\n",
            "the loss in 19000th batch is: 6.152422\n",
            "the loss in 19200th batch is: 5.703742\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new_features.py --model=GRU --epoch=5         ##lambda_ = 0.1##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwJTcMfg0E5r",
        "outputId": "20f1612f-824b-4d93-bb07-117665a45180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-23 15:33:37.212332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-23 15:33:37.212382: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-23 15:33:37.212420: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-23 15:33:37.220413: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-23 15:33:38.483893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:82: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:81: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:585: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/legacy_cells.py:599: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "2023-11-23 15:33:48.755863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:49.279751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:49.280100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:49.281924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:49.282210: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:49.282471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:51.735091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:51.735486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:51.735706: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-11-23 15:33:51.735823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:33:51.738777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:209: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:212: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/RL_HW3/SA2C_code/Kaggle/SNQN_new_features.py:214: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.hidden_feature = tf.compat.v1.layers.dense(self.feature_vec,self.hidden_size,use_bias=True,activation = None)\n",
            "2023-11-23 15:34:00.825779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:34:00.826082: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:34:00.826260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:34:00.826489: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:34:00.826722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 15:34:00.826882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13742 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2023-11-23 15:34:01.440168: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 2.600000\n",
            "clicks hr ndcg @ 5 : 0.000068, 0.000038\n",
            "purchase hr and ndcg @5 : 0.000189, 0.000073\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 4.800000\n",
            "clicks hr ndcg @ 10 : 0.000161, 0.000068\n",
            "purchase hr and ndcg @10 : 0.000189, 0.000073\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5.600000\n",
            "clicks hr ndcg @ 15 : 0.000194, 0.000077\n",
            "purchase hr and ndcg @15 : 0.000189, 0.000073\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 7.400000\n",
            "clicks hr ndcg @ 20 : 0.000270, 0.000095\n",
            "purchase hr and ndcg @20 : 0.000189, 0.000073\n",
            "#############################################################\n",
            "2023-11-23 15:50:04.218749: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-23 15:50:05.345218: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-23 15:50:05.436195: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-23 15:50:05.526108: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "2023-11-23 15:50:05.614217: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141704000 exceeds 10% of free system memory.\n",
            "the loss in 200th batch is: 10.810688\n",
            "the loss in 400th batch is: 10.766116\n",
            "the loss in 600th batch is: 10.438708\n",
            "the loss in 800th batch is: 10.335717\n",
            "the loss in 1000th batch is: 10.058101\n",
            "the loss in 1200th batch is: 9.892952\n",
            "the loss in 1400th batch is: 9.949819\n",
            "the loss in 1600th batch is: 9.792624\n",
            "the loss in 1800th batch is: 9.831453\n",
            "the loss in 2000th batch is: 9.756437\n",
            "the loss in 2200th batch is: 9.234982\n",
            "the loss in 2400th batch is: 9.464724\n",
            "the loss in 2600th batch is: 8.927677\n",
            "the loss in 2800th batch is: 9.221754\n",
            "the loss in 3000th batch is: 8.911826\n",
            "the loss in 3200th batch is: 8.664929\n",
            "the loss in 3400th batch is: 9.235084\n",
            "the loss in 3600th batch is: 8.772291\n",
            "the loss in 3800th batch is: 8.559640\n",
            "the loss in 4000th batch is: 8.443638\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 4367.400000\n",
            "clicks hr ndcg @ 5 : 0.124947, 0.093622\n",
            "purchase hr and ndcg @5 : 0.266679, 0.208255\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 5326.400000\n",
            "clicks hr ndcg @ 10 : 0.155715, 0.103583\n",
            "purchase hr and ndcg @10 : 0.310338, 0.222378\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 5887.600000\n",
            "clicks hr ndcg @ 15 : 0.173770, 0.108359\n",
            "purchase hr and ndcg @15 : 0.335664, 0.229094\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 6287.200000\n",
            "clicks hr ndcg @ 20 : 0.186263, 0.111309\n",
            "purchase hr and ndcg @20 : 0.355320, 0.233735\n",
            "#############################################################\n",
            "the loss in 4200th batch is: 8.541647\n",
            "the loss in 4400th batch is: 8.652704\n",
            "the loss in 4600th batch is: 8.492193\n",
            "the loss in 4800th batch is: 8.090535\n",
            "the loss in 5000th batch is: 8.713962\n",
            "the loss in 5200th batch is: 8.017609\n",
            "the loss in 5400th batch is: 7.910615\n",
            "the loss in 5600th batch is: 7.949432\n",
            "the loss in 5800th batch is: 8.078854\n",
            "the loss in 6000th batch is: 7.829365\n",
            "the loss in 6200th batch is: 7.599793\n",
            "the loss in 6400th batch is: 7.469518\n",
            "the loss in 6600th batch is: 7.728565\n",
            "the loss in 6800th batch is: 7.750568\n",
            "the loss in 7000th batch is: 7.426603\n",
            "the loss in 7200th batch is: 7.199121\n",
            "the loss in 7400th batch is: 7.247192\n",
            "the loss in 7600th batch is: 7.709560\n",
            "the loss in 7800th batch is: 7.010396\n",
            "the loss in 8000th batch is: 7.679602\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6111.400000\n",
            "clicks hr ndcg @ 5 : 0.177227, 0.133483\n",
            "purchase hr and ndcg @5 : 0.362502, 0.290289\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 7480.000000\n",
            "clicks hr ndcg @ 10 : 0.221713, 0.147890\n",
            "purchase hr and ndcg @10 : 0.422226, 0.309749\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 8244.000000\n",
            "clicks hr ndcg @ 15 : 0.246691, 0.154501\n",
            "purchase hr and ndcg @15 : 0.454923, 0.318377\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 8752.200000\n",
            "clicks hr ndcg @ 20 : 0.263774, 0.158534\n",
            "purchase hr and ndcg @20 : 0.474579, 0.323012\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 7.362982\n",
            "the loss in 8400th batch is: 7.358236\n",
            "the loss in 8600th batch is: 7.023926\n",
            "the loss in 8800th batch is: 7.387325\n",
            "the loss in 9000th batch is: 6.968161\n",
            "the loss in 9200th batch is: 7.390127\n",
            "the loss in 9400th batch is: 6.828413\n",
            "the loss in 9600th batch is: 7.035067\n",
            "the loss in 9800th batch is: 6.481316\n",
            "the loss in 10000th batch is: 6.747775\n",
            "the loss in 10200th batch is: 6.758762\n",
            "the loss in 10400th batch is: 6.942511\n",
            "the loss in 10600th batch is: 6.238237\n",
            "the loss in 10800th batch is: 7.052922\n",
            "the loss in 11000th batch is: 6.588609\n",
            "the loss in 11200th batch is: 6.640115\n",
            "the loss in 11400th batch is: 6.429980\n",
            "the loss in 11600th batch is: 6.290940\n",
            "the loss in 11800th batch is: 6.466523\n",
            "the loss in 12000th batch is: 6.689336\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6802.000000\n",
            "clicks hr ndcg @ 5 : 0.197792, 0.147164\n",
            "purchase hr and ndcg @5 : 0.401058, 0.313606\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8307.000000\n",
            "clicks hr ndcg @ 10 : 0.247156, 0.163121\n",
            "purchase hr and ndcg @10 : 0.464751, 0.334135\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9198.000000\n",
            "clicks hr ndcg @ 15 : 0.276444, 0.170885\n",
            "purchase hr and ndcg @15 : 0.502174, 0.344072\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 9786.200000\n",
            "clicks hr ndcg @ 20 : 0.296443, 0.175608\n",
            "purchase hr and ndcg @20 : 0.523909, 0.349199\n",
            "#############################################################\n",
            "the loss in 12200th batch is: 6.928897\n",
            "the loss in 12400th batch is: 6.922531\n",
            "the loss in 12600th batch is: 6.721089\n",
            "the loss in 12800th batch is: 6.730036\n",
            "the loss in 13000th batch is: 6.647619\n",
            "the loss in 13200th batch is: 6.582860\n",
            "the loss in 13400th batch is: 5.978827\n",
            "the loss in 13600th batch is: 6.593814\n",
            "the loss in 13800th batch is: 6.288637\n",
            "the loss in 14000th batch is: 6.770619\n",
            "the loss in 14200th batch is: 6.040876\n",
            "the loss in 14400th batch is: 6.533299\n",
            "the loss in 14600th batch is: 6.267795\n",
            "the loss in 14800th batch is: 5.911104\n",
            "the loss in 15000th batch is: 6.668318\n",
            "the loss in 15200th batch is: 6.314655\n",
            "the loss in 15400th batch is: 6.457023\n",
            "the loss in 15600th batch is: 6.322277\n",
            "the loss in 15800th batch is: 6.486045\n",
            "the loss in 16000th batch is: 6.121535\n",
            "#############################################################\n",
            "total clicks: 118306, total purchase:5291\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7091.800000\n",
            "clicks hr ndcg @ 5 : 0.206448, 0.152672\n",
            "purchase hr and ndcg @5 : 0.417123, 0.328107\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 8644.400000\n",
            "clicks hr ndcg @ 10 : 0.257316, 0.169144\n",
            "purchase hr and ndcg @10 : 0.483084, 0.349475\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 9538.200000\n",
            "clicks hr ndcg @ 15 : 0.286849, 0.176959\n",
            "purchase hr and ndcg @15 : 0.519940, 0.359219\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 10174.600000\n",
            "clicks hr ndcg @ 20 : 0.308632, 0.182108\n",
            "purchase hr and ndcg @20 : 0.542809, 0.364616\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 5.757510\n",
            "the loss in 16400th batch is: 6.048599\n",
            "the loss in 16600th batch is: 5.799908\n",
            "the loss in 16800th batch is: 5.344625\n",
            "the loss in 17000th batch is: 6.321118\n",
            "the loss in 17200th batch is: 5.781747\n",
            "the loss in 17400th batch is: 6.086412\n",
            "the loss in 17600th batch is: 5.957067\n",
            "the loss in 17800th batch is: 5.714621\n",
            "the loss in 18000th batch is: 5.923587\n",
            "the loss in 18200th batch is: 6.047592\n",
            "the loss in 18400th batch is: 5.787780\n",
            "the loss in 18600th batch is: 6.025889\n",
            "the loss in 18800th batch is: 6.218285\n",
            "the loss in 19000th batch is: 5.904903\n",
            "the loss in 19200th batch is: 5.932470\n"
          ]
        }
      ],
      "source": [
        "! python SNQN_new_features.py --model=GRU --epoch=5 ##lambda_ = 0.15##"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbtNPk6y7YhgkvxXoxFlu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}